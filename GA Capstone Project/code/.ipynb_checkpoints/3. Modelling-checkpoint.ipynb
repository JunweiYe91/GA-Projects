{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5b0549",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone: Credit Card Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b9af5",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem Statement\n",
    "You've want to sign up for a credit card that best fits you, but you've realised that you will need to comb through all card descriptions, conditions and reviews in order to decide which card is the best. You find that it is very inconvenient and as a data scientist, you decide to take it upon yourself to build a credit card recommender.\n",
    "\n",
    "Use different techniques to analyse the reviews, credit card conditions to derive a credit card recommender that could help to save a lot of time when choosing a credit card."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b01d0",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Datasets Used](#Datasets-Used)\n",
    "- [Extraction of Data](#Extraction-of-Data)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Data Dictionary](#Data-Dictionary)\n",
    "- [Pre-processing text data](#Pre-processing-text-data)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Sentiment Analysis Using BERT](#Sentiment-Analysis-Using-BERT)\n",
    "- [Preparing the dataset for modelling](#Preparing-the-dataset-for-modelling)\n",
    "- [Modelling](#Modelling)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03cce1f",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d50c64",
   "metadata": {},
   "source": [
    "All credit cards in Singapore offer some sort of reward for using them for your purchases, which include incentives like cashback, reward points (which can be traded for air miles, discount vouchers or actual products), or airline miles. However, the most common reward, and perhaps the most enticing, would perhaps be cashback.\n",
    "\n",
    "For the uninitiated, cashback refers to receiving back a percentage of what you spend in the form of money. It is akin to getting a perpetual discount whenever you spend. Sounds too good to be true? It really is not. Credit card companies are constantly competing to provide the most competitive rewards for their customers - some cards offer lucrative sign-up promotions, while others offer higher cashbacks for niche spending categories like travel or sustainability.\n",
    "\n",
    "With so many cards available on the market to choose from, it is no wonder that Singaporeans have a hard time deciding which is the best credit card in Singapore. In particular, it is hard to compare the different cashback rewards across multiple categories for various credit cards. [(source)](https://sg.news.yahoo.com/three-reasons-why-own-credit-104237659.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9440014",
   "metadata": {},
   "source": [
    "## Datasets Used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76bff5",
   "metadata": {},
   "source": [
    "Data in this used in the analysis consists of credit card details and reviews scrapped from various websites. Please rerefer to the data dictionary for more information on the columns extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6273032",
   "metadata": {},
   "source": [
    "## Extraction of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c5ba53",
   "metadata": {},
   "source": [
    "Please refer to \"**1. Extraction of Data**\" for the steps done for data extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64591a",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06df8f7",
   "metadata": {},
   "source": [
    "Please refer to \"**2. Analysis of Datasets**\" for the steps done for data import and cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd48258",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee89854",
   "metadata": {},
   "source": [
    "<br>**Dataset name: `cashback_expand_df`**\n",
    "<br>This dataset contains all the reviews on cashback credit cards.\n",
    "\n",
    "| Feature | Type | Dataset | Description |\n",
    "|:--|:-:|:-:|:--|\n",
    "|credit_card_name|string|perfumes_df|Name of the credit card.|\n",
    "|card_type|string|perfumes_df|Type of credit card. Cashback of Air Miles.|\n",
    "|reviews|string|perfumes_df|Reviews on the credit cards.|\n",
    "\n",
    "\n",
    "<br>**Dataset name: `miles_expand_df`**\n",
    "<br>This dataset contains all the reviews on air miles credit cards.\n",
    "\n",
    "| Feature | Type | Dataset | Description |\n",
    "|:--|:-:|:-:|:--|\n",
    "|credit_card_name|string|perfumes_df|Name of the credit card.|\n",
    "|card_type|string|perfumes_df|Type of credit card. Cashback of Air Miles.|\n",
    "|reviews|string|perfumes_df|Reviews on the credit cards.|\n",
    "\n",
    "<br>**Dataset name: `combined_expand_df`**\n",
    "<br>This dataset contains all the reviews on all credit cards.\n",
    "\n",
    "| Feature | Type | Dataset | Description |\n",
    "|:--|:-:|:-:|:--|\n",
    "|credit_card_name|string|perfumes_df|Name of the credit card.|\n",
    "|card_type|string|perfumes_df|Type of credit card. Cashback of Air Miles.|\n",
    "|reviews|string|perfumes_df|Reviews on the credit cards.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897c61d",
   "metadata": {},
   "source": [
    "## Pre processing text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676d4bd",
   "metadata": {},
   "source": [
    "Please refer to \"**2. Analysis of Datasets**\" for the steps done for pre-processing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ba5cc",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156c413",
   "metadata": {},
   "source": [
    "Please refer to \"**2. Analysis of Datasets**\" for the steps done for exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf5391",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948c13b",
   "metadata": {},
   "source": [
    "Please refer to \"**2. Analysis of Datasets**\" for the steps done for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da6653",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f61f3b",
   "metadata": {},
   "source": [
    "**1. Importing of libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff8d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "# Chart plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelling libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "\n",
    "# Streamlit\n",
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97be30f",
   "metadata": {},
   "source": [
    "**2. Convert features into numerical format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2ab09f",
   "metadata": {},
   "source": [
    "In order to perform modelling, we will have to convert our dataset back into multiple-choice format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94e002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported the original completed questionaires\n",
    "cashback_questionaire_df = pd.read_csv('../dataset/3. cashback_questionaire_responses.csv')\n",
    "miles_questionaire_df = pd.read_csv('../dataset/3. miles_questionaire_responses.csv')\n",
    "\n",
    "# Import the dataset\n",
    "cashback_converted_df = pd.read_csv('../dataset/3. cashback_converted_df.csv')\n",
    "miles_converted_df = pd.read_csv('../dataset/3. miles_converted_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb03c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cashback Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_1</th>\n",
       "      <th>ques_2</th>\n",
       "      <th>ques_3</th>\n",
       "      <th>ques_4</th>\n",
       "      <th>ques_5</th>\n",
       "      <th>ques_6</th>\n",
       "      <th>ques_7</th>\n",
       "      <th>ques_8</th>\n",
       "      <th>ques_9</th>\n",
       "      <th>ques_10</th>\n",
       "      <th>ques_11</th>\n",
       "      <th>card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>uob_one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>uob_one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>uob_one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>uob_one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>uob_one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_1  ques_2  ques_3  ques_4  ques_5  ques_6  ques_7  ques_8  ques_9  \\\n",
       "0       1       1       3       1       2       6       3       7       1   \n",
       "1       1       2       6       2       5       2       4       6       4   \n",
       "2       1       2       3       5       5       1       2       6       7   \n",
       "3       1       2       6       4       7       7       2       5       2   \n",
       "4       1       2       6       5       6       7       4       5       5   \n",
       "\n",
       "   ques_10  ques_11     card  \n",
       "0        6        1  uob_one  \n",
       "1        2        1  uob_one  \n",
       "2        6        1  uob_one  \n",
       "3        1        1  uob_one  \n",
       "4        7        1  uob_one  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miles Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ques_1</th>\n",
       "      <th>ques_2</th>\n",
       "      <th>ques_3</th>\n",
       "      <th>ques_4</th>\n",
       "      <th>ques_5</th>\n",
       "      <th>ques_6</th>\n",
       "      <th>ques_7</th>\n",
       "      <th>ques_8</th>\n",
       "      <th>ques_9</th>\n",
       "      <th>ques_10</th>\n",
       "      <th>ques_11</th>\n",
       "      <th>card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>citi_rewards_miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>uob_prvi_miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>dbs_altitude_visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>citi_rewards_miles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>dbs_altitude_visa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ques_1  ques_2  ques_3  ques_4  ques_5  ques_6  ques_7  ques_8  ques_9  \\\n",
       "0       2       2       6       5       7       6       4       4       7   \n",
       "1       2       1       5       3       4       1       1       1       7   \n",
       "2       2       2       5       1       3       2       1       2       6   \n",
       "3       2       2       7       1       2       5       3       4       7   \n",
       "4       2       1       2       5       3       2       2       3       3   \n",
       "\n",
       "   ques_10  ques_11                card  \n",
       "0        1        8  citi_rewards_miles  \n",
       "1        7        2      uob_prvi_miles  \n",
       "2        3        5   dbs_altitude_visa  \n",
       "3        2        7  citi_rewards_miles  \n",
       "4        6        5   dbs_altitude_visa  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the card column in cashback_questionaire_df and miles_questionaire_df\n",
    "cashback_questionaire_df['card'] = cashback_converted_df['card']\n",
    "miles_questionaire_df['card'] = miles_converted_df['card']\n",
    "\n",
    "# Display the two datasets after the changes above\n",
    "print('Cashback Dataset:')\n",
    "display(cashback_questionaire_df.head())\n",
    "print('Miles Dataset:')\n",
    "display(miles_questionaire_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c627ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Combined the two dataset into one combined dataset\n",
    "combined_questionaire_df = pd.merge(cashback_questionaire_df, miles_questionaire_df, how = 'outer')\n",
    "\n",
    "# Check the total number of rows to ensure that the dataset has been merged correctly\n",
    "print(combined_questionaire_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f1cd9",
   "metadata": {},
   "source": [
    "**3. Convert target column into numerical format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc4bfe",
   "metadata": {},
   "source": [
    "Since the model isn't able to read text, we will also need to convert our target column into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e346111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert subreddit labels to binary\n",
    "combined_questionaire_df['label'] = combined_questionaire_df['card'].map({\n",
    "    'not_eligible': 1, \n",
    "    'hsbc_advance': 2, \n",
    "    'posb_everyday_cashback': 3, \n",
    "    'sc_spree_card': 4,\n",
    "    'uob_one': 5, \n",
    "    'citi_rewards_miles': 6, \n",
    "    'dbs_altitude_visa': 7, \n",
    "    'dbs_womans_world_miles': 8, \n",
    "    'uob_prvi_miles': 9, })\n",
    "\n",
    "# Check that all the target variables have been converted\n",
    "label_cat = sns.countplot(x='label', data=combined_questionaire_df, palette='husl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68cdff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each column, load in only if it is not 'card' and 'return'\n",
    "features = [col for col in combined_questionaire_df.columns if col != 'card' and col != 'label']\n",
    "X = combined_questionaire_df[features]\n",
    "y = combined_questionaire_df['label']\n",
    "\n",
    "# Train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced9ce0",
   "metadata": {},
   "source": [
    "Now that we have prepared the dataset, let'start with modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1745e",
   "metadata": {},
   "source": [
    "**4. Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e4dbd",
   "metadata": {},
   "source": [
    "We will use the below models to make the prediction:\n",
    "- K Nearest Neighbour\n",
    "- Random Forest Classifier\n",
    "- Ada Boost Classifier\n",
    "- Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa50842",
   "metadata": {},
   "source": [
    "**K Nearest Neighbour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2886c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross Validation Score: 0.742\n",
      "KNN Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a class instance of KNN class with an initial parameter value\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'KNN Cross Validation Score: {round(cross_val_score(knn, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(f'KNN Test Score: {round(accuracy_score(y_test, y_pred_knn),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269466b",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e71c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Validation Score: 0.941\n",
      "Random Forest Test Score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features=\"auto\",random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Random Forest Cross Validation Score: {round(cross_val_score(rf, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(f'Random Forest Test Score: {round(accuracy_score(y_test, y_pred_rf),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b465b9a",
   "metadata": {},
   "source": [
    "**Ada Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe887b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Cross Validation Score: 0.752\n",
      "Ada Boost Test Score: 0.768\n"
     ]
    }
   ],
   "source": [
    "# Train the Ada Boost Model\n",
    "ab = AdaBoostClassifier(n_estimators=100)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Ada Boost Cross Validation Score: {round(cross_val_score(ab, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_ab = ab.predict(X_test)\n",
    "print(f'Ada Boost Test Score: {round(accuracy_score(y_test, y_pred_ab),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825b22e",
   "metadata": {},
   "source": [
    "**Gradient Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8123da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Cross Validation Score: 0.953\n",
      "Gradient Boost Test Score: 0.831\n"
     ]
    }
   ],
   "source": [
    "# Train the Gradient Boost Model\n",
    "gb = GradientBoostingClassifier(n_estimators=100)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Gradient Boost Cross Validation Score: {round(cross_val_score(gb, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "print(f'Gradient Boost Test Score: {round(accuracy_score(y_test, y_pred_gb),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cda867",
   "metadata": {},
   "source": [
    "**Train-Test Summary Score:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af9258",
   "metadata": {},
   "source": [
    "The scores are as per below:\n",
    "\n",
    "| Model | Train Results | Test Results |\n",
    "|:--|:-:|:-:|\n",
    "|K Nearest Neighbour|0.742|0.750|\n",
    "|**<font color = blue>Random Forest</font>**|**<font color = blue>0.943</font>**|**<font color = blue>0.945</font>**|\n",
    "|Ada Boost|0.752|0.768|\n",
    "|Gradient Boost|0.953|0.831|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bba33b",
   "metadata": {},
   "source": [
    "The first round of train and test results looks rather promosing. The best performing model is the Random Forest Classifier with a train result of 0.943 and a test result of 0.945. Gradient Boost Classifier had a higher train result of 0..953 but there seems to be overfitting as the difference between the train result and test result is more than 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280cccd",
   "metadata": {},
   "source": [
    "**5. Addressing Class Imbalance using Smote**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fb1b3",
   "metadata": {},
   "source": [
    "SMOTE stands for Synthetic Minority Oversampling Technique. SMOTE is an oversampling technique where the synthetic samples are generated for the minority class. This algorithm helps to overcome the overfitting problem posed by random oversampling. It focuses on the feature space to generate new instances with the help of interpolation between the positive instances that lie together. [(source)](https://www.analyticsvidhya.com/blog/2020/10/overcoming-class-imbalance-using-smote-techniques/)\n",
    "\n",
    "Due to imbalanced data, it is possible to make a model that appears very accurate, while it actually is useless. This is because traditional machine learning models and evaluation metrics that assume a balanced class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20869c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution before applying SMOTE:\n",
      "5    1237\n",
      "6     639\n",
      "9     394\n",
      "7     356\n",
      "3     173\n",
      "1     128\n",
      "8      62\n",
      "2       7\n",
      "4       4\n",
      "\n",
      "\n",
      "Distribution after applying SMOTE:\n",
      "6    1237\n",
      "7    1237\n",
      "5    1237\n",
      "9    1237\n",
      "2    1237\n",
      "1    1237\n",
      "8    1237\n",
      "3    1237\n",
      "4    1237\n"
     ]
    }
   ],
   "source": [
    "# Value counts before applying smote\n",
    "print('Distribution before applying SMOTE:')\n",
    "print(y_train.value_counts().to_string())\n",
    "\n",
    "#Oversampling the data\n",
    "smote = SMOTE(random_state = 42, k_neighbors = 3)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check that smote has been applied to X_train and y_train\n",
    "print('Distribution after applying SMOTE:')\n",
    "print(y_train_smote.value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93005cc8",
   "metadata": {},
   "source": [
    "**K Nearest Neighbour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82e7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross Validation Score: 0.742\n",
      "KNN Test Score: 0.711\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a class instance of KNN class with an initial parameter value\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'KNN Cross Validation Score: {round(cross_val_score(knn, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "print(f'KNN Test Score: {round(knn.score(X_test, y_test),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe5cd1",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae0b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Validation Score: 0.941\n",
      "Random Forest Test Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features=\"auto\",random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Random Forest Cross Validation Score: {round(cross_val_score(rf, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(f'Random Forest Test Score: {round(accuracy_score(y_test, y_pred_rf),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442803c7",
   "metadata": {},
   "source": [
    "**Ada Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b74c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Cross Validation Score: 0.752\n",
      "Ada Boost Test Score: 0.456\n"
     ]
    }
   ],
   "source": [
    "# Train the Ada Boost Model\n",
    "ab = AdaBoostClassifier(n_estimators=100)\n",
    "ab.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Ada Boost Cross Validation Score: {round(cross_val_score(ab, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_ab = ab.predict(X_test)\n",
    "print(f'Ada Boost Test Score: {round(accuracy_score(y_test, y_pred_ab),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced96c5",
   "metadata": {},
   "source": [
    "**Gradient Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9721c192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Cross Validation Score: 0.953\n",
      "Gradient Boost Test Score: 0.938\n"
     ]
    }
   ],
   "source": [
    "# Train the Gradient Boost Model\n",
    "gb = GradientBoostingClassifier(n_estimators=100)\n",
    "gb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Gradient Boost Cross Validation Score: {round(cross_val_score(gb, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "print(f'Gradient Boost Test Score: {round(accuracy_score(y_test, y_pred_gb),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe6f98",
   "metadata": {},
   "source": [
    "**Train-Test Summary Score (After Applying Smote):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4a3c0",
   "metadata": {},
   "source": [
    "The scores are as per below:\n",
    "\n",
    "| Model | Train Results | Test Results |\n",
    "|:--|:-:|:-:|\n",
    "|K Nearest Neighbour Classifier|0.742|0.711|\n",
    "|Random Forest Classifier|0.943|0.934|\n",
    "|Ada Boost Classifier|0.752|0.456|\n",
    "|**<font color = blue>Gradient Boost Classifier</font>**|**<font color = blue>0.953</font>**|**<font color = blue>0.938</font>**|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb04a8",
   "metadata": {},
   "source": [
    "After applying SMOTE, the all the test scores have decreased. This could be due to the class imbalance which have been addressed by applying SMOTE. Gradient Boost Classifier seems to be the best performing model now with a train result of 0.953 and a test result of 0.938. Ada Boost Classifier seems to be severly overfitted as the difference between the train result and test result is almost 0.3.\n",
    "\n",
    "Now, let's apply GridSearchCV to further optimise the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842cefb",
   "metadata": {},
   "source": [
    "**6. Optimising the models using GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7af99",
   "metadata": {},
   "source": [
    "**K Nearest Neighbour**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "609d5eaa",
   "metadata": {},
   "source": [
    "knn_params = {\n",
    "    'n_neighbors': [5, 10, 30, 50, 100, 200, 300],                      \n",
    "    'weights': ['distance', 'uniform'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],                   \n",
    "    'leaf_size': [10, 20, 30, 50, 100],\n",
    "    'p': [1, 2]\n",
    "    }\n",
    "    \n",
    "model = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Best param value:\")\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8e9b7",
   "metadata": {},
   "source": [
    "We have ran the above code and have obtained the these as the best parameters for K Nearest Neighbour:\n",
    "\n",
    "`{'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa3454",
   "metadata": {},
   "source": [
    "We will load the above parameters into K Nearest Neighbour to generate the optimised model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9f00016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Cross Validation Score: 0.801\n",
      "KNN Test Score: 0.763\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a class instance of KNN class with an initial parameter value\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights = 'distance', algorithm = 'auto', leaf_size = 20, p = 1 )\n",
    "knn.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'KNN Cross Validation Score: {round(cross_val_score(knn, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "print(f'KNN Test Score: {round(knn.score(X_test, y_test),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975ae9e",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cd5b4b0",
   "metadata": {},
   "source": [
    "rf_params = {\n",
    "    'n_estimators':[10, 20, 50, 100, 200, 300],                     \n",
    "    'max_depth':[10, 20, 30, 40, 50, 100, 150],                         \n",
    "    'min_samples_leaf': [1, 5, 10, 20]\n",
    "    }\n",
    "\n",
    "model = GridSearchCV(RandomForestClassifier(), rf_params, cv=5)\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Best param value:\")\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d774e",
   "metadata": {},
   "source": [
    "We have ran the above code and have obtained the these as the best parameters for Random Forest Classifier:\n",
    "\n",
    "`{'max_depth': 40, 'min_samples_leaf': 1, 'n_estimators': 50}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aacb2dd",
   "metadata": {},
   "source": [
    "We will load the above parameters into Random Forest Classifier to generate the optimised model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65ce0cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Cross Validation Score: 0.941\n",
      "Random Forest Test Score: 0.934\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest Model\n",
    "rfr = RandomForestClassifier(n_estimators=50, max_features=\"auto\", max_depth = 40, \n",
    "                            min_samples_leaf = 1, random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Random Forest Cross Validation Score: {round(cross_val_score(rf, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(f'Random Forest Test Score: {round(accuracy_score(y_test, y_pred_rf),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb0477f",
   "metadata": {},
   "source": [
    "**Ada Boost Classifier**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95b226af",
   "metadata": {},
   "source": [
    "ada_params = {\n",
    "    'n_estimators':[10, 50, 100, 200, 300],                     \n",
    "    'learning_rate':[1, 2, 3, 5, 10, 20, 30]\n",
    "    }\n",
    "\n",
    "model = GridSearchCV(AdaBoostClassifier(), ada_params, cv=5)\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Best param value:\")\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee6531",
   "metadata": {},
   "source": [
    "We have ran the above code and have obtained the these as the best parameters for Ada Boost Classifier:\n",
    "\n",
    "`{'learning_rate': 3, 'n_estimators': 300}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e89c1",
   "metadata": {},
   "source": [
    "We will load the above parameters into Random Forest Classifier to generate the optimised model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26be2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Cross Validation Score: 0.848\n",
      "Ada Boost Test Score: 0.798\n"
     ]
    }
   ],
   "source": [
    "# Train the Ada Boost Model\n",
    "ab = AdaBoostClassifier(n_estimators=300, learning_rate = 3)\n",
    "ab.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Ada Boost Cross Validation Score: {round(cross_val_score(ab, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_ab = ab.predict(X_test)\n",
    "print(f'Ada Boost Test Score: {round(accuracy_score(y_test, y_pred_ab),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fded0db0",
   "metadata": {},
   "source": [
    "**Gradient Boost Classifier**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29030612",
   "metadata": {},
   "source": [
    "gb_params = {\n",
    "    'loss':['log_loss', 'exponential'],                     \n",
    "    'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.0, 0.5, 1]\n",
    "    }\n",
    "\n",
    "model = GridSearchCV(GradientBoostingClassifier(), gb_params, cv=5)\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "print(\"Best param value:\")\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9913ae0",
   "metadata": {},
   "source": [
    "We have ran the above code and have obtained the these as the best parameters for Gradient Boost Classifier:\n",
    "\n",
    "`{'learning_rate': 0.1, 'loss': 'log_loss', 'n_estimators': 200, 'subsample': 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904b4db",
   "metadata": {},
   "source": [
    "We will load the above parameters into Gradient Boost Classifier to generate the optimised model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63b5298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Cross Validation Score: 0.949\n",
      "Gradient Boost Test Score: 0.944\n"
     ]
    }
   ],
   "source": [
    "# Train the Gradient Boost Model\n",
    "gb = GradientBoostingClassifier(n_estimators = 200, loss = 'log_loss', subsample = 1, learning_rate = 0.1)\n",
    "gb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Derive the cross-val score for training set\n",
    "print(f'Gradient Boost Cross Validation Score: {round(cross_val_score(gb, X_train, y_train, cv=5).mean(),3)}')\n",
    "\n",
    "# Check the test score\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "print(f'Gradient Boost Test Score: {round(accuracy_score(y_test, y_pred_gb),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf00827",
   "metadata": {},
   "source": [
    "**Train-Test Summary Score (After Performing GridSearchCV):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30514841",
   "metadata": {},
   "source": [
    "| Model | Train Results | Test Results |\n",
    "|:--|:-:|:-:|\n",
    "|K Nearest Neighbour|0.801|0.763|\n",
    "|**<font color = blue>Random Forest Classifier</font>**|**<font color = blue>0.941</font>**|**<font color = blue>0.931</font>**|\n",
    "|Ada Boost Classifier|0.869|0.821|\n",
    "|Gradient Boost Classifier|0.949|0.944|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5e164",
   "metadata": {},
   "source": [
    "After performing GridSearchCV, Gradient Boost Classifier has the best performing train and test with a result of 0.949 and 0.944 respectively. However, we would choose Random Forest Classifier as our preferred choice of model. This is because the restuls for the Random Forest Classifier is also relatively good with a train and test result of 0.941 and 0.931 respectively. However, the model takes considerably lesser time to run. Considering that we will be deploying this on a live website, a faster model will be preferred as user experience will definitely be better. Since the results are not significantly different, we would choose the slightly less accurate but faster model as our preferred choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846159a",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71aa9b",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "- Recommender deployed successfully on https://keycards.herokuapp.com/\n",
    "- The recommender is fuss free way to select the best suited credit cards. The recommender uses a Random Forest Model with a model accuracy of 94%.\n",
    "- Besides card return, customers service is also quite an important factor when determining a good credit card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce4c64",
   "metadata": {},
   "source": [
    "### Limitations and Future Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709f7fe",
   "metadata": {},
   "source": [
    "- Analysis is only limited to all the reviews that have been successfully scrapped. Suggest extracting reviews from other sites as well.\n",
    "- Recommender only has 8 cards at the moment. To include more credit cards in the future.\n",
    "- Recommender could be scaled to include credit cards for other countries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
