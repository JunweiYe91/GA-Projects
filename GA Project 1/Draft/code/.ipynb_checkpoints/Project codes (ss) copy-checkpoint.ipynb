{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new format for the SAT was released in March 2016. As an employee of the College Board - the organization that administers the SAT - you are a part of a team that tracks statewide participation and recommends where money is best spent to improve SAT participation rates. The College Board wants to start some initiatives to increase the participation rate and has tasked you to identify states where they should start.\n",
    "\n",
    "Identify the states that has the most potential to increase the SAT participation rate and make recommendations to the College Board on where the efforts should be focused on. Give some recommendations on what could be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAT and ACT are standardized tests that many colleges and universities in the United States require for their admissions process. This score is used along with other materials such as grade point average (GPA) and essay responses to determine whether or not a potential student will be accepted to the university.\n",
    "\n",
    "The SAT has two sections of the test: Evidence-Based Reading and Writing and Math ([*source*](https://www.princetonreview.com/college/sat-sections)). The ACT has 4 sections: English, Mathematics, Reading, and Science, with an additional optional writing section ([*source*](https://www.act.org/content/act/en/products-and-services/the-act/scores/understanding-your-scores.html)). They have different score ranges, which you can read more about on their websites or additional outside sources (a quick Google search will help you understand the scores for each test):\n",
    "* [SAT](https://collegereadiness.collegeboard.org/sat)\n",
    "* [ACT](https://www.act.org/content/act/en.html)\n",
    "\n",
    "Standardized tests have long been a controversial topic for students, administrators, and legislators. Since the 1940's, an increasing number of colleges have been using scores from students' performances on tests like the SAT and the ACT as a measure for college readiness and aptitude ([*source*](https://www.minotdailynews.com/news/local-news/2017/04/a-brief-history-of-the-sat-and-act/)). Supporters of these tests argue that these scores can be used as an objective measure to determine college admittance. Opponents of these tests claim that these tests are not accurate measures of students potential or ability and serve as an inequitable barrier to entry. Lately, more and more schools are opting to drop the SAT/ACT requirement for their Fall 2021 applications ([*read more about this here*](https://www.cnn.com/2020/04/14/us/coronavirus-colleges-sat-act-test-trnd/index.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information used for the analysis\n",
    "\n",
    "Both SAT and ACT are widely used for colleges and university admissions in the United States and neither SAT or ACT is harder than the other. Universities use both tests as academic measures to compare students. They are similar in difficulty with a comparable level of challenge. Most colleges will back this up, stating both tests are equally challenging. ([*source*](https://www.crimsoneducation.org/sg/blog/test-prep/sat-vs-act-whats-the-difference/#:~:text=Is%20the%20ACT%20easier%20than,both%20tests%20are%20equally%20challenging))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets used\n",
    "\n",
    "For the purpose of the analysis, we have used the **\"2017 - 2019 ACT Scores by State\"** datasets and **\"2017 - 2019 SAT Scores by State\"** datasets. \n",
    "\n",
    "Information found in the \"ACT Scores by State\" datasets includes the participation rate, scores for English, Math, Reading, Science and the Composite score which is obtained by summing the scores for each of the four sections.\n",
    "\n",
    "Information found in the \"SAT Scores by State\" datasets includes the participation rate, scores for Evidence-Based Reading and Writing (EBRW), Math and the Total score which is the sum of the scores for EBRW and Math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Information Used\n",
    "\n",
    "Additional information are extracted from the below sources:\n",
    "- To update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to manually calculate mean:\n",
    "\n",
    "def cal_mean(list_of_numbers):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for number in list_of_numbers:\n",
    "        sum = sum + number\n",
    "        count = count + 1\n",
    "    return sum/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to manually calculate standard deviation\n",
    "\n",
    "def cal_std_dev(list_of_numbers):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for number in list_of_numbers:\n",
    "        count = count + 1\n",
    "        sum = sum + (number - cal_mean(list_of_numbers))**2\n",
    "    return (sum/count)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentage to float\n",
    "\n",
    "def convert_percentage(value):\n",
    "    return float(value.replace('%',\"\"))/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets:\n",
    "act_2017 = pd.read_csv(\"../data/act_2017.csv\")\n",
    "act_2018 = pd.read_csv(\"../data/act_2018.csv\")\n",
    "act_2019 = pd.read_csv(\"../data/act_2019.csv\")\n",
    "sat_2017 = pd.read_csv(\"../data/sat_2017.csv\")\n",
    "sat_2018 = pd.read_csv(\"../data/sat_2018.csv\")\n",
    "sat_2019 = pd.read_csv(\"../data/sat_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Datasets used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT 2017:\n",
      "      State Participation  English  Math  Reading  Science Composite\n",
      "0  National           60%     20.3  20.7     21.4     21.0      21.0\n",
      "1   Alabama          100%     18.9  18.4     19.7     19.4      19.2\n",
      "2    Alaska           65%     18.7  19.8     20.4     19.9      19.8\n",
      "3   Arizona           62%     18.6  19.8     20.1     19.8      19.7\n",
      "4  Arkansas          100%     18.9  19.0     19.7     19.5      19.4\n",
      "\n",
      "ACT 2018:\n",
      "        State Participation  Composite\n",
      "0     Alabama          100%       19.1\n",
      "1      Alaska           33%       20.8\n",
      "2     Arizona           66%       19.2\n",
      "3    Arkansas          100%       19.4\n",
      "4  California           27%       22.7\n",
      "\n",
      "ACT 2019:\n",
      "        State Participation  Composite\n",
      "0     Alabama          100%       18.9\n",
      "1      Alaska           38%       20.1\n",
      "2     Arizona           73%       19.0\n",
      "3    Arkansas          100%       19.3\n",
      "4  California           23%       22.6\n",
      "\n",
      "SAT 2017:\n",
      "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
      "0     Alabama            5%                                 593   572   1165\n",
      "1      Alaska           38%                                 547   533   1080\n",
      "2     Arizona           30%                                 563   553   1116\n",
      "3    Arkansas            3%                                 614   594   1208\n",
      "4  California           53%                                 531   524   1055\n",
      "\n",
      "SAT 2018:\n",
      "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
      "0     Alabama            6%                                 595   571   1166\n",
      "1      Alaska           43%                                 562   544   1106\n",
      "2     Arizona           29%                                 577   572   1149\n",
      "3    Arkansas            5%                                 592   576   1169\n",
      "4  California           60%                                 540   536   1076\n",
      "\n",
      "SAT 2019:\n",
      "        State Participation Rate  EBRW  Math  Total\n",
      "0     Alabama                 7%   583   560   1143\n",
      "1      Alaska                41%   556   541   1097\n",
      "2     Arizona                31%   569   565   1134\n",
      "3    Arkansas                 6%   582   559   1141\n",
      "4  California                63%   534   531   1065\n"
     ]
    }
   ],
   "source": [
    "# Display Data:\n",
    "print(\"ACT 2017:\")\n",
    "print(act_2017.head())\n",
    "print(\"\")\n",
    "print(\"ACT 2018:\")\n",
    "print(act_2018.head())\n",
    "print(\"\")\n",
    "print(\"ACT 2019:\")\n",
    "print(act_2019.head())\n",
    "print(\"\")\n",
    "print(\"SAT 2017:\")\n",
    "print(sat_2017.head())\n",
    "print(\"\")\n",
    "print(\"SAT 2018:\")\n",
    "print(sat_2018.head())\n",
    "print(\"\")\n",
    "print(\"SAT 2019:\")\n",
    "print(sat_2019.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data cleaning steps taken:**\n",
    "- Renaming of columns for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "\n",
    "# Rename column \"Evidence-Based Reading and Writing\" for 'SAT 2017' and 'SAT 2018'\n",
    "# Rename column \"Participation Rate\" for 'SAT 2019'\n",
    "\n",
    "sat_2017.rename(columns = {'Evidence-Based Reading and Writing': 'EBRW', 'Total': 'Total_SAT'}, inplace = True)\n",
    "sat_2018.rename(columns = {'Evidence-Based Reading and Writing': 'EBRW', 'Total': 'Total_SAT'}, inplace = True)\n",
    "sat_2019.rename(columns = {'Participation Rate': 'Participation', 'Total': 'Total_SAT'}, inplace = True)\n",
    "\n",
    "# Drop columns \"English\", \"Math\", \"Reading\". \"Science\" in 'ACT 2017'\n",
    "act_2017.drop('English', axis = 1, inplace = True)\n",
    "act_2017.drop('Math', axis = 1, inplace = True)\n",
    "act_2017.drop('Reading', axis = 1, inplace = True)\n",
    "act_2017.drop('Science', axis = 1, inplace = True)\n",
    "\n",
    "# Adding year to the dataset\n",
    "\n",
    "act_2017['Year'] = 2017\n",
    "act_2018['Year'] = 2018\n",
    "act_2019['Year'] = 2019\n",
    "sat_2017['Year'] = 2017\n",
    "sat_2018['Year'] = 2018\n",
    "sat_2019['Year'] = 2019\n",
    "\n",
    "# Remove alphabets found in \"Composite\" column in 'ACT 2017' \n",
    "# Convert data in \"Composite\" in 'ACT 2017' from string to float\n",
    "\n",
    "act_2017['Composite'] = act_2017['Composite'].str.replace(\"x\", \"\")\n",
    "act_2017['Composite'] = act_2017['Composite'].astype(float)\n",
    "\n",
    "# Merge the datasets\n",
    "sat_2017_to_2019 = pd.merge(sat_2017, sat_2018, how = 'outer')\n",
    "sat_2017_to_2019 = pd.merge(sat_2017_to_2019, sat_2019, how = 'outer')\n",
    "act_2017_to_2019 = pd.merge(act_2017, act_2018, how = 'outer')\n",
    "act_2017_to_2019 = pd.merge(act_2017_to_2019, act_2019, how = 'outer')\n",
    "\n",
    "# Format and convert \"Participation\" column in 'ACT 2017 to 2019' to float\n",
    "#act_2017_to_2019[\"Participation\"] = act_2017_to_2019[\"Participation\"].str.replace(\"%\", \"\")\n",
    "#act_2017_to_2019[\"Participation\"] = act_2017_to_2019[\"Participation\"].astype(float)/100\n",
    "\n",
    "# Format and convert \"Participation\" column in 'ACT 2017 to 2019' to float\n",
    "act_2017_to_2019[\"Participation\"] = act_2017_to_2019[\"Participation\"].map(lambda Participation: cal_std_dev(Par) )\n",
    "act_2017_to_2019[\"Participation\"] = act_2017_to_2019[\"Participation\"].astype(float)/100\n",
    "\n",
    "# Clean, format and convert \"Participation\" column in 'SAT 2017 to 2019' to float\n",
    "#sat_2017_to_2019[\"Participation\"] = sat_2017_to_2019[\"Participation\"].str.replace(\"%\", \"\")\n",
    "#sat_2017_to_2019[\"Participation\"] = sat_2017_to_2019[\"Participation\"].map(lambda Participation: np.nan if Participation == \"—\" else float (Participation)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_2017_to_2019.to_csv('../data/sat_2017_to_2019.csv')\n",
    "act_2017_to_2019.to_csv('../data/act_2017_to_2019.csv')\n",
    "combined.to_csv('../data/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Participation_SAT    EBRW_SAT    Math_SAT    Total_SAT         Year\n",
      "count         153.000000  153.000000  153.000000   153.000000   153.000000\n",
      "mean            0.448693  564.535948  552.019608  1119.732026  2018.000000\n",
      "std             0.370944   46.301362   63.246434    94.162654     0.819178\n",
      "min             0.020000  480.000000   52.000000   943.000000  2017.000000\n",
      "25%             0.040000  531.000000  521.000000  1053.000000  2017.000000\n",
      "50%             0.500000  554.000000  546.000000  1099.000000  2018.000000\n",
      "75%             0.760000  614.000000  596.000000  1210.000000  2019.000000\n",
      "max             1.000000  644.000000  655.000000  1298.000000  2019.000000\n",
      "\n",
      "       Participation_ACT   Total_ACT         Year\n",
      "count         156.000000  156.000000   156.000000\n",
      "mean            0.614551   21.501282  2018.000000\n",
      "std             0.334412    2.087010     0.819126\n",
      "min             0.060000   17.700000  2017.000000\n",
      "25%             0.290000   19.800000  2017.000000\n",
      "50%             0.655000   21.250000  2018.000000\n",
      "75%             1.000000   23.625000  2019.000000\n",
      "max             1.000000   25.600000  2019.000000\n"
     ]
    }
   ],
   "source": [
    "print(sat_2017_to_2019.describe())\n",
    "print(\"\")\n",
    "print(act_2017_to_2019.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**\n",
    "\n",
    "*Note*: if you are unsure of what a feature is, check the source of the data! This can be found in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data dictionary\n",
    "\n",
    "data_dict = {\n",
    "    \"act_2017_to_2019\": {\n",
    "        \"State\":{\n",
    "            \"Type\": \"string\",\n",
    "            \"Description\": \"States found in the United States.\"\n",
    "        },\n",
    "        \"Participation_ACT\":{\n",
    "            \"Type\": \"float\",\n",
    "            \"Description\": \"% of the population taking ACT.\"\n",
    "        },\n",
    "        \"Total_ACT\":{\n",
    "            \"Type\": \"float\",\n",
    "            \"Description\": \"Overall score obtained by summing the scores of all the ACT sections.\"\n",
    "        },\n",
    "        \"Year\":{\n",
    "            \"Type\": \"int\",\n",
    "            \"Description\": \"The year the data pertains to.\"\n",
    "        },\n",
    "    },\n",
    "    \"sat_2017_to_2019\": {\n",
    "        \"State\":{\n",
    "            \"Type\": \"string\",\n",
    "            \"Description\": \"States found in the United States.\"\n",
    "        },\n",
    "        \"Participation_SAT\":{\n",
    "            \"Type\": \"float\",\n",
    "            \"Description\": \"% of the population taking SAT.\"\n",
    "        },\n",
    "        \"EBRW_SAT\":{\n",
    "            \"Type\": \"int\",\n",
    "            \"Description\": \"Score for the Evidence-Based Reading and Writing section.\"\n",
    "        },\n",
    "        \"Math_SAT\":{\n",
    "            \"Type\": \"int\",\n",
    "            \"Description\": \"Score for the Math section.\"\n",
    "        },\n",
    "        \"Total_SAT\":{\n",
    "            \"Type\": \"int\",\n",
    "            \"Description\": \"Overall score obtained by summing the scores of all the SAT sections.\"\n",
    "        },\n",
    "        \"Year\":{\n",
    "            \"Type\": \"int\",\n",
    "            \"Description\": \"The year the data pertains to.\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit the table below to create your own data dictionary for the datasets you chose.*\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|State|string|act_2017_to_2019|States found in the United States.|\n",
    "|Participation_ACT|float|act_2017_to_2019|% of the population taking ACT.|\n",
    "|Total_ACT|float|act_2017_to_2019|Overall score obtained by summing the scores of all the ACT sections.|\n",
    "|Year|int|act_2017_to_2019|The year the data pertains to.|\n",
    "|||||\n",
    "|State|string|sat_2017_to_2019|States found in the United States.|\n",
    "|Participation_SAT|float|sat_2017_to_2019|% of the population taking SAT.|\n",
    "|EBRW_SAT|int|sat_2017_to_2019|Score for the Evidence-Based Reading and Writing section.|\n",
    "|Math_SAT|int|sat_2017_to_2019|Score for the Math section.|\n",
    "|Total_SAT|int|sat_2017_to_2019|Overall score obtained by summing the scores of all the SAT sections.|\n",
    "|Year|int|sat_2017_to_2019|The year the data pertains to.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for ACT 2017 to 2019:\n",
      "       Participation_ACT   Total_ACT         Year\n",
      "count         156.000000  156.000000   156.000000\n",
      "mean            0.614551   21.501282  2018.000000\n",
      "std             0.334412    2.087010     0.819126\n",
      "min             0.060000   17.700000  2017.000000\n",
      "25%             0.290000   19.800000  2017.000000\n",
      "50%             0.655000   21.250000  2018.000000\n",
      "75%             1.000000   23.625000  2019.000000\n",
      "max             1.000000   25.600000  2019.000000\n",
      "\n",
      "\n",
      "\n",
      "Summary Statistics for SAT 2017 to 2019:\n",
      "       Participation_SAT    EBRW_SAT    Math_SAT    Total_SAT         Year\n",
      "count         153.000000  153.000000  153.000000   153.000000   153.000000\n",
      "mean            0.448693  564.535948  552.019608  1119.732026  2018.000000\n",
      "std             0.370944   46.301362   63.246434    94.162654     0.819178\n",
      "min             0.020000  480.000000   52.000000   943.000000  2017.000000\n",
      "25%             0.040000  531.000000  521.000000  1053.000000  2017.000000\n",
      "50%             0.500000  554.000000  546.000000  1099.000000  2018.000000\n",
      "75%             0.760000  614.000000  596.000000  1210.000000  2019.000000\n",
      "max             1.000000  644.000000  655.000000  1298.000000  2019.000000\n"
     ]
    }
   ],
   "source": [
    "# Showing the summary statistics:\n",
    "print(\"Summary Statistics for ACT 2017 to 2019:\")\n",
    "print(act_2017_to_2019.describe())\n",
    "print(\"\\n\\n\")\n",
    "print(\"Summary Statistics for SAT 2017 to 2019:\")\n",
    "print(sat_2017_to_2019.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Participation_ACT': 0.33333847998985355, 'Total_ACT': 2.080310232642433, 'Year': 0.816496580927726}\n",
      "{'Participation_SAT': 0.3697299717899723, 'EBRW_SAT': 46.14980241905189, 'Math_SAT': 63.039407800152446, 'Total_SAT': 93.8544281331918, 'Year': 0.816496580927726}\n"
     ]
    }
   ],
   "source": [
    "# Use a dictionary comprehension to apply the standard deviation to each numeric column in the dataframe. \n",
    "sd_act_2017_to_2019 = {key: cal_std_dev(value) for key,value in act_2017_to_2019.iloc[:, 1:].items()}\n",
    "print(sd_act_2017_to_2019)\n",
    "\n",
    "sd_sat_2017_to_2019 = {key: cal_std_dev(value) for key,value in sat_2017_to_2019.iloc[:, 1:].items()}\n",
    "print(sd_sat_2017_to_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Which states have the highest and lowest participation rates for the 2019 SAT and ACT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States with Highest and Lowest Participation Rate for ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with the lowest participation rate for ACT 2019:\n",
      "\n",
      "     State  Participation_ACT  Total_ACT  Year\n",
      "123  Maine               0.06       24.3  2019\n",
      "\n",
      "\n",
      "\n",
      "States with the highest participation rate for ACT 2019:\n",
      "\n",
      "              State  Participation_ACT  Total_ACT  Year\n",
      "104         Alabama                1.0       18.9  2019\n",
      "107        Arkansas                1.0       19.3  2019\n",
      "121        Kentucky                1.0       19.8  2019\n",
      "122       Louisiana                1.0       18.8  2019\n",
      "128     Mississippi                1.0       18.4  2019\n",
      "130         Montana                1.0       19.8  2019\n",
      "131        Nebraska                1.0       20.0  2019\n",
      "132          Nevada                1.0       17.9  2019\n",
      "137  North Carolina                1.0       19.0  2019\n",
      "139            Ohio                1.0       20.0  2019\n",
      "140        Oklahoma                1.0       18.9  2019\n",
      "146       Tennessee                1.0       19.4  2019\n",
      "148            Utah                1.0       20.3  2019\n",
      "153       Wisconsin                1.0       20.3  2019\n",
      "154         Wyoming                1.0       19.8  2019\n"
     ]
    }
   ],
   "source": [
    "act_2019 = act_2017_to_2019[act_2017_to_2019['Year'] == 2019]\n",
    "act_min_state_2019 = act_2019[act_2019['Participation_ACT'] == act_2019['Participation_ACT'].min()]\n",
    "act_max_state_2019 = act_2019[act_2019['Participation_ACT'] == act_2019['Participation_ACT'].max()]\n",
    "\n",
    "print('States with the lowest participation rate for ACT 2019:')\n",
    "print(\"\")\n",
    "print(act_min_state_2019)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print('States with the highest participation rate for ACT 2019:')\n",
    "print(\"\")\n",
    "print(act_max_state_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States with Highest and Lowest Participation Rate for SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with the lowest participation rate for SAT 2019:\n",
      "\n",
      "            State  Participation_SAT  EBRW_SAT  Math_SAT  Total_SAT  Year\n",
      "136  North Dakota               0.02       627       636       1263  2019\n",
      "\n",
      "\n",
      "\n",
      "States with the highest participation rate for SAT 2019:\n",
      "\n",
      "            State  Participation_SAT  EBRW_SAT  Math_SAT  Total_SAT  Year\n",
      "107      Colorado                1.0       518       506       1024  2019\n",
      "108   Connecticut                1.0       529       516       1046  2019\n",
      "109      Delaware                1.0       499       486        985  2019\n",
      "111       Florida                1.0       516       483        999  2019\n",
      "114         Idaho                1.0       505       488        993  2019\n",
      "115      Illinois                1.0       509       504       1013  2019\n",
      "124      Michigan                1.0       507       496       1003  2019\n",
      "142  Rhode Island                1.0       503       492        995  2019\n"
     ]
    }
   ],
   "source": [
    "sat_2019 = sat_2017_to_2019[sat_2017_to_2019['Year'] == 2019]\n",
    "sat_min_state_2019 = sat_2019[sat_2019['Participation_SAT'] == sat_2019['Participation_SAT'].min()]\n",
    "sat_max_state_2019 = sat_2019[sat_2019['Participation_SAT'] == sat_2019['Participation_SAT'].max()]\n",
    "\n",
    "print('States with the lowest participation rate for SAT 2019:')\n",
    "print(\"\")\n",
    "print(sat_min_state_2019)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print('States with the highest participation rate for SAT 2019:')\n",
    "print(\"\")\n",
    "print(sat_max_state_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Which states have the highest and lowest mean total/composite scores for the 2017, 2018 or 2019 SAT and ACT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States with Highest and Lowest mean Total Score for ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with the lowest mean Total Scores for ACT:\n",
      "\n",
      "State\n",
      "Nevada    17.8\n",
      "\n",
      "\n",
      "\n",
      "States with the highest mean Total Scores for ACT:\n",
      "\n",
      "State\n",
      "Massachusetts    25.466667\n"
     ]
    }
   ],
   "source": [
    "act_mean = act_2017_to_2019.groupby('State')['Total_ACT'].mean()\n",
    "act_min_mean = act_mean[act_mean == act_mean.min()]\n",
    "act_max_mean = act_mean[act_mean == act_mean.max()]\n",
    "\n",
    "print('States with the lowest mean Total Scores for ACT:')\n",
    "print(\"\")\n",
    "print(act_min_mean.to_string())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print('States with the highest mean Total Scores for ACT:')\n",
    "print(\"\")\n",
    "print(act_max_mean.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States with Highest and Lowest mean Total Score for SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with the lowest mean Total Scores for SAT:\n",
      "\n",
      "State\n",
      "District of Columbia    967.333333\n",
      "\n",
      "\n",
      "\n",
      "States with the highest mean Total Scores for SAT:\n",
      "\n",
      "State\n",
      "Minnesota    1292.333333\n"
     ]
    }
   ],
   "source": [
    "sat_mean = sat_2017_to_2019.groupby('State')['Total_SAT'].mean()\n",
    "sat_min_mean = sat_mean[sat_mean == sat_mean.min()]\n",
    "sat_max_mean = sat_mean[sat_mean == sat_mean.max()]\n",
    "\n",
    "print('States with the lowest mean Total Scores for SAT:')\n",
    "print(\"\")\n",
    "print(sat_min_mean.to_string())\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print('States with the highest mean Total Scores for SAT:')\n",
    "print(\"\")\n",
    "print(sat_max_mean.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Do any states with 100% participation on a given test have a rate change year-to-year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States with 100% Participation for ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with 100% Participation for 2017:\n",
      "\n",
      "Year            2017  2018  2019\n",
      "State                           \n",
      "Alabama          1.0  1.00  1.00\n",
      "Arkansas         1.0  1.00  1.00\n",
      "Colorado         1.0  0.30  0.27\n",
      "Kentucky         1.0  1.00  1.00\n",
      "Louisiana        1.0  1.00  1.00\n",
      "Minnesota        1.0  0.99  0.95\n",
      "Mississippi      1.0  1.00  1.00\n",
      "Missouri         1.0  1.00  0.82\n",
      "Montana          1.0  1.00  1.00\n",
      "Nevada           1.0  1.00  1.00\n",
      "North Carolina   1.0  1.00  1.00\n",
      "Oklahoma         1.0  1.00  1.00\n",
      "South Carolina   1.0  1.00  0.78\n",
      "Tennessee        1.0  1.00  1.00\n",
      "Utah             1.0  1.00  1.00\n",
      "Wisconsin        1.0  1.00  1.00\n",
      "Wyoming          1.0  1.00  1.00\n",
      "\n",
      "\n",
      "\n",
      "States with 100% Participation for 2018:\n",
      "\n",
      "Year            2017  2018  2019\n",
      "State                           \n",
      "Alabama         1.00   1.0  1.00\n",
      "Arkansas        1.00   1.0  1.00\n",
      "Kentucky        1.00   1.0  1.00\n",
      "Louisiana       1.00   1.0  1.00\n",
      "Mississippi     1.00   1.0  1.00\n",
      "Missouri        1.00   1.0  0.82\n",
      "Montana         1.00   1.0  1.00\n",
      "Nebraska        0.84   1.0  1.00\n",
      "Nevada          1.00   1.0  1.00\n",
      "North Carolina  1.00   1.0  1.00\n",
      "Ohio            0.75   1.0  1.00\n",
      "Oklahoma        1.00   1.0  1.00\n",
      "South Carolina  1.00   1.0  0.78\n",
      "Tennessee       1.00   1.0  1.00\n",
      "Utah            1.00   1.0  1.00\n",
      "Wisconsin       1.00   1.0  1.00\n",
      "Wyoming         1.00   1.0  1.00\n",
      "\n",
      "\n",
      "\n",
      "States with 100% Participation for 2019:\n",
      "\n",
      "Year            2017  2018  2019\n",
      "State                           \n",
      "Alabama         1.00   1.0   1.0\n",
      "Arkansas        1.00   1.0   1.0\n",
      "Kentucky        1.00   1.0   1.0\n",
      "Louisiana       1.00   1.0   1.0\n",
      "Mississippi     1.00   1.0   1.0\n",
      "Montana         1.00   1.0   1.0\n",
      "Nebraska        0.84   1.0   1.0\n",
      "Nevada          1.00   1.0   1.0\n",
      "North Carolina  1.00   1.0   1.0\n",
      "Ohio            0.75   1.0   1.0\n",
      "Oklahoma        1.00   1.0   1.0\n",
      "Tennessee       1.00   1.0   1.0\n",
      "Utah            1.00   1.0   1.0\n",
      "Wisconsin       1.00   1.0   1.0\n",
      "Wyoming         1.00   1.0   1.0\n"
     ]
    }
   ],
   "source": [
    "# States with 100% Participation for 2017\n",
    "pivot = pd.pivot_table(act_2017_to_2019, values=['Participation_ACT'],index=['State'], columns = [\"Year\"], aggfunc='sum')\n",
    "pivot_2017 = pivot[pivot['Participation_ACT'][2017] == 1]\n",
    "\n",
    "print(\"States with 100% Participation for 2017:\")\n",
    "print(\"\")\n",
    "print(pivot_2017.Participation_ACT)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# States with 100% Participation for 2017\n",
    "pivot = pd.pivot_table(act_2017_to_2019, values=['Participation_ACT'],index=['State'], columns = [\"Year\"], aggfunc='sum')\n",
    "pivot_2018 = pivot[pivot['Participation_ACT'][2018] == 1]\n",
    "\n",
    "print(\"States with 100% Participation for 2018:\")\n",
    "print(\"\")\n",
    "print(pivot_2018.Participation_ACT)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# States with 100% Participation for 2017\n",
    "pivot = pd.pivot_table(act_2017_to_2019, values=['Participation_ACT'],index=['State'], columns = [\"Year\"], aggfunc='sum')\n",
    "pivot_2019 = pivot[pivot['Participation_ACT'][2019] == 1]\n",
    "\n",
    "print(\"States with 100% Participation for 2019:\")\n",
    "print(\"\")\n",
    "print(pivot_2019.Participation_ACT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### States with 100% Participation for SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with 100% Participation for 2017:\n",
      "\n",
      "Year                  2017  2018  2019\n",
      "State                                 \n",
      "Connecticut            1.0  1.00  1.00\n",
      "Delaware               1.0  1.00  1.00\n",
      "District of Columbia   1.0  0.92  0.94\n",
      "Michigan               1.0  1.00  1.00\n",
      "\n",
      "\n",
      "\n",
      "States with 100% Participation for 2018:\n",
      "\n",
      "Year         2017  2018  2019\n",
      "State                        \n",
      "Colorado     0.11   1.0   1.0\n",
      "Connecticut  1.00   1.0   1.0\n",
      "Delaware     1.00   1.0   1.0\n",
      "Idaho        0.93   1.0   1.0\n",
      "Michigan     1.00   1.0   1.0\n",
      "\n",
      "\n",
      "\n",
      "States with 100% Participation for 2019:\n",
      "\n",
      "Year          2017  2018  2019\n",
      "State                         \n",
      "Colorado      0.11  1.00   1.0\n",
      "Connecticut   1.00  1.00   1.0\n",
      "Delaware      1.00  1.00   1.0\n",
      "Florida       0.83  0.56   1.0\n",
      "Idaho         0.93  1.00   1.0\n",
      "Illinois      0.09  0.99   1.0\n",
      "Michigan      1.00  1.00   1.0\n",
      "Rhode Island  0.71  0.97   1.0\n"
     ]
    }
   ],
   "source": [
    "# States with 100% Participation for 2017\n",
    "pivot = pd.pivot_table(sat_2017_to_2019, values=['Participation_SAT'],index=['State'], columns = [\"Year\"], aggfunc='sum')\n",
    "pivot_2017 = pivot[pivot['Participation_SAT'][2017] == 1]\n",
    "\n",
    "print(\"States with 100% Participation for 2017:\")\n",
    "print(\"\")\n",
    "print(pivot_2017.Participation_SAT)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# States with 100% Participation for 2017\n",
    "pivot = pd.pivot_table(sat_2017_to_2019, values=['Participation_SAT'],index=['State'], columns = [\"Year\"], aggfunc='sum')\n",
    "pivot_2018 = pivot[pivot['Participation_SAT'][2018] == 1]\n",
    "\n",
    "print(\"States with 100% Participation for 2018:\")\n",
    "print(\"\")\n",
    "print(pivot_2018.Participation_SAT)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# States with 100% Participation for 2017\n",
    "pivot = pd.pivot_table(sat_2017_to_2019, values=['Participation_SAT'],index=['State'], columns = [\"Year\"], aggfunc='sum')\n",
    "pivot_2019 = pivot[pivot['Participation_SAT'][2019] == 1]\n",
    "\n",
    "print(\"States with 100% Participation for 2019:\")\n",
    "print(\"\")\n",
    "print(pivot_2019.Participation_SAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Do any states show have >50% participation on both tests each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States with >50% participation on both tests in 2017:\n",
      "\n",
      "Florida\n",
      "Georgia\n",
      " Hawaii\n",
      "\n",
      "\n",
      "\n",
      "States with >50% participation on both tests in 2018:\n",
      "\n",
      "       Florida\n",
      "       Georgia\n",
      "        Hawaii\n",
      "North Carolina\n",
      "South Carolina\n",
      "\n",
      "\n",
      "\n",
      "States with >50% participation on both tests in 2019:\n",
      "\n",
      "       Florida\n",
      "        Hawaii\n",
      "North Carolina\n",
      "South Carolina\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter for states with >50% participation on both tests\n",
    "filtered_combined = combined[combined[\"Participation_ACT\"] > 0.5]\n",
    "filtered_combined = filtered_combined[filtered_combined[\"Participation_SAT\"] > 0.5]\n",
    "\n",
    "print(\"States with >50% participation on both tests in 2017:\")\n",
    "print(\"\")\n",
    "print(filtered_combined[filtered_combined[\"Year\"] == 2017]['State'].to_string(index = False))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"States with >50% participation on both tests in 2018:\")\n",
    "print(\"\")\n",
    "print(filtered_combined[filtered_combined[\"Year\"] == 2018]['State'].to_string(index = False))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"States with >50% participation on both tests in 2019:\")\n",
    "print(\"\")\n",
    "print(filtered_combined[filtered_combined[\"Year\"] == 2019]['State'].to_string(index = False))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your conclusions and recommendations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
